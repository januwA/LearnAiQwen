import os
from pathlib import Path
from typing import Dict, List
from core.interfaces import IVectorStore

class RagEngine:
    """
    åº”ç”¨å±‚ï¼šå¤„ç†ç´¢å¼•é€»è¾‘å’Œæ£€ç´¢æµç¨‹ã€‚
    """
    def __init__(
        self,
        vector_store: IVectorStore,
        chunk_size: int = 1200,
        chunk_overlap: int = 200,
        min_score: float = 0.12,
    ):
        self.vector_store = vector_store
        self.chunk_size = chunk_size
        self.chunk_overlap = min(chunk_overlap, max(0, chunk_size - 1))
        self.min_score = min_score

    def _iter_chunks(self, text: str):
        step = max(1, self.chunk_size - self.chunk_overlap)
        for start in range(0, len(text), step):
            end = start + self.chunk_size
            yield start, end, text[start:end]

    def index_project(self, directory: str = "."):
        """
        è‡ªåŠ¨æ‰«æå¹¶ç´¢å¼•é¡¹ç›®ä¸­çš„ä»£ç æ–‡ä»¶
        """
        docs: List[Dict[str, str | int]] = []
        base_dir = Path(directory).resolve()
        ignored_tokens = {".git", ".venv", "__pycache__", ".cache"}

        # åªç´¢å¼•å…·æœ‰ä»£è¡¨æ„ä¹‰çš„æ–‡ä»¶ï¼Œä¿ç•™å…ƒæ•°æ®ä¾›æ£€ç´¢åå¼•ç”¨
        for root, _, files in os.walk(directory):
            if any(token in root for token in ignored_tokens):
                continue
            for file in files:
                if file.endswith((".py", ".toml", ".md")):
                    path = os.path.join(root, file)
                    try:
                        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                            rel_path = str(Path(path).resolve().relative_to(base_dir))
                            for idx, (start, end, chunk) in enumerate(self._iter_chunks(content), start=1):
                                text = chunk.strip()
                                if not text:
                                    continue
                                docs.append({
                                    "text": text,
                                    "file": file,
                                    "path": rel_path,
                                    "chunk_id": idx,
                                    "start": start,
                                    "end": min(end, len(content)),
                                })
                    except OSError as exc:
                        print(f"âš ï¸ è·³è¿‡æ–‡ä»¶å¤±è´¥: {path} ({exc})")
        self.vector_store.add_documents(docs)

    def get_related_context(self, query: str) -> str:
        results = self.vector_store.query(query, top_k=3)
        filtered = [r for r in results if float(r.get("score", 0.0)) >= self.min_score]
        if not filtered:
            return "\n[é€šçŸ¥] RAG æ‰«æå®Œæˆï¼šæœªå‘ç°ä¸æ­¤è¯·æ±‚ç›´æ¥ç›¸å…³çš„æœ¬åœ°ä»£ç ç‰‡æ®µã€‚è¯·åŸºäºå¸¸è¯†æˆ–å·²åˆ†æçš„å†…å®¹å›ç­”ã€‚"

        context = "\n--- ğŸ“š RAG æ£€ç´¢åˆ°çš„å‚è€ƒä»£ç  (æ ‡æ³¨æ¥æº) ---\n"
        for i, doc in enumerate(filtered, start=1):
            score = float(doc.get("score", 0.0))
            path = doc.get("path", "<unknown>")
            chunk_id = doc.get("chunk_id", "?")
            text = str(doc.get("text", "")).strip()
            context += (
                f"\n[å‚è€ƒ {i}] è·¯å¾„: {path} | åˆ†å—: {chunk_id} | ç›¸ä¼¼åº¦: {score:.3f}\n"
                f"{text}\n"
            )
        context += "\n----------------------------------------"
        return context
