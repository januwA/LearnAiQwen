import os
import numpy as np
import faiss
from typing import List
from sentence_transformers import SentenceTransformer
from core.interfaces import IVectorStore

class FaissVectorStore(IVectorStore):
    """
    åŸºäº FAISS å’Œ Sentence-Transformers çš„å·¥ä¸šçº§æœ¬åœ°å‘é‡å­˜å‚¨ã€‚
    ä½¿ç”¨ CPU ç´¢å¼•ï¼Œå¤„ç†ä¸‡çº§æ–‡æ¡£æå¿«ã€‚
    """
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        # åŠ è½½è½»é‡çº§è¯­ä¹‰å‘é‡åµŒå…¥æ¨¡å‹
        print(f"ğŸ§  æ­£åœ¨åŠ è½½ Embeddings æ¨¡å‹: {model_name}...")
        self.model = SentenceTransformer(model_name)
        self.dimension = self.model.get_sentence_embedding_dimension()
        self.index = faiss.IndexFlatL2(self.dimension)
        self.documents = []

    def add_documents(self, documents: List[str]):
        if not documents: return
        # è¯­ä¹‰å‘é‡åŒ–
        embeddings = self.model.encode(documents)
        self.index.add(np.array(embeddings).astype('float32'))
        self.documents.extend(documents)
        print(f"ğŸ“š RAG-FAISS: å·²å®Œæˆ {len(documents)} æ¡æ–‡æ¡£æ¡ç›®çš„è¯­ä¹‰ç´¢å¼•")

    def query(self, text: str, top_k: int = 3) -> List[str]:
        if not self.documents: return []
        
        # å°†æœç´¢è¯å‘é‡åŒ–
        query_vector = self.model.encode([text])
        distances, indices = self.index.search(np.array(query_vector).astype('float32'), top_k)
        
        results = []
        for i in indices[0]:
            if i != -1 and i < len(self.documents):
                results.append(self.documents[i])
        return results
